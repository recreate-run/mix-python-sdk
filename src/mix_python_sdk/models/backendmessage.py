"""Code generated by Speakeasy (https://speakeasy.com). DO NOT EDIT."""

from __future__ import annotations
from .callbackresultdata import CallbackResultData, CallbackResultDataTypedDict
from .toolcalldata import ToolCallData, ToolCallDataTypedDict
from mix_python_sdk.types import BaseModel, UNSET_SENTINEL
import pydantic
from pydantic import model_serializer
from typing import List, Optional
from typing_extensions import Annotated, NotRequired, TypedDict


class BackendMessageTypedDict(TypedDict):
    r"""Backend message structure representing a complete message exchange"""

    id: str
    r"""Unique message identifier"""
    role: str
    r"""Message role (user, assistant, tool)"""
    session_id: str
    r"""Session identifier"""
    user_input: str
    r"""User's input message"""
    assistant_response: NotRequired[str]
    r"""Assistant's response message (optional)"""
    cache_creation_tokens: NotRequired[int]
    r"""Tokens used for prompt cache creation (optional)"""
    cache_read_tokens: NotRequired[int]
    r"""Tokens read from prompt cache (optional)"""
    callback_results: NotRequired[List[CallbackResultDataTypedDict]]
    r"""Callback execution results (optional)"""
    cost: NotRequired[float]
    r"""Cost for this specific message in USD"""
    input_tokens: NotRequired[int]
    r"""Input tokens used for this message (includes cache creation)"""
    model: NotRequired[str]
    r"""Model used for this message (e.g., 'claude-sonnet-4')"""
    output_tokens: NotRequired[int]
    r"""Output tokens generated for this message (includes cache reads)"""
    reasoning: NotRequired[str]
    r"""Reasoning process (optional)"""
    reasoning_duration: NotRequired[int]
    r"""Reasoning duration in milliseconds (optional)"""
    tool_calls: NotRequired[List[ToolCallDataTypedDict]]
    r"""Tool calls made during message processing"""


class BackendMessage(BaseModel):
    r"""Backend message structure representing a complete message exchange"""

    id: str
    r"""Unique message identifier"""

    role: str
    r"""Message role (user, assistant, tool)"""

    session_id: Annotated[str, pydantic.Field(alias="sessionId")]
    r"""Session identifier"""

    user_input: Annotated[str, pydantic.Field(alias="userInput")]
    r"""User's input message"""

    assistant_response: Annotated[
        Optional[str], pydantic.Field(alias="assistantResponse")
    ] = None
    r"""Assistant's response message (optional)"""

    cache_creation_tokens: Annotated[
        Optional[int], pydantic.Field(alias="cacheCreationTokens")
    ] = None
    r"""Tokens used for prompt cache creation (optional)"""

    cache_read_tokens: Annotated[
        Optional[int], pydantic.Field(alias="cacheReadTokens")
    ] = None
    r"""Tokens read from prompt cache (optional)"""

    callback_results: Annotated[
        Optional[List[CallbackResultData]], pydantic.Field(alias="callbackResults")
    ] = None
    r"""Callback execution results (optional)"""

    cost: Optional[float] = None
    r"""Cost for this specific message in USD"""

    input_tokens: Annotated[Optional[int], pydantic.Field(alias="inputTokens")] = None
    r"""Input tokens used for this message (includes cache creation)"""

    model: Optional[str] = None
    r"""Model used for this message (e.g., 'claude-sonnet-4')"""

    output_tokens: Annotated[Optional[int], pydantic.Field(alias="outputTokens")] = None
    r"""Output tokens generated for this message (includes cache reads)"""

    reasoning: Optional[str] = None
    r"""Reasoning process (optional)"""

    reasoning_duration: Annotated[
        Optional[int], pydantic.Field(alias="reasoningDuration")
    ] = None
    r"""Reasoning duration in milliseconds (optional)"""

    tool_calls: Annotated[
        Optional[List[ToolCallData]], pydantic.Field(alias="toolCalls")
    ] = None
    r"""Tool calls made during message processing"""

    @model_serializer(mode="wrap")
    def serialize_model(self, handler):
        optional_fields = set(
            [
                "assistantResponse",
                "cacheCreationTokens",
                "cacheReadTokens",
                "callbackResults",
                "cost",
                "inputTokens",
                "model",
                "outputTokens",
                "reasoning",
                "reasoningDuration",
                "toolCalls",
            ]
        )
        serialized = handler(self)
        m = {}

        for n, f in type(self).model_fields.items():
            k = f.alias or n
            val = serialized.get(k)

            if val != UNSET_SENTINEL:
                if val is not None or k not in optional_fields:
                    m[k] = val

        return m
